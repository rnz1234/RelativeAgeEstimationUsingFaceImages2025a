{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b44d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# importing the sys module\n",
    "import sys        \n",
    " \n",
    "# appending the directory of mod.py\n",
    "# in the sys.path list\n",
    "sys.path.append('../')   \n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from Common.Optimizers.RangerLars import RangerLars\n",
    "from Common.Schedulers.GradualWarmupScheduler import GradualWarmupScheduler\n",
    "\n",
    "import diff_pipeline4__config as cfg\n",
    "#diff_pipeline4__dataset_simple\n",
    "from diff_pipeline4__dataset_copy import DiffPipeline4SameUniformDiffDataset, DiffPipeline4MixedUniformDiffDataset, DiffPipeline4MimicDiffDataset, get_error_constrained_dataset\n",
    "from Common.Datasets.Morph2.data_parser import DataParser\n",
    "from diff_pipeline4__train import train_diff_cls_model_iter\n",
    "\n",
    "\n",
    "from diff_pipeline4__model import DiffPipeline4Model, DiffPipeline4DeepModel, AgeDiffModel, DiffModelConfigType\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import utils\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#           Preparations\n",
    "#####################################################\n",
    "\n",
    "torch.manual_seed(cfg.RANDOM_SEED)\n",
    "np.random.seed(cfg.RANDOM_SEED)\n",
    "random.seed(cfg.RANDOM_SEED)\n",
    "\n",
    "# if cfg.USE_GPU:\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# else:\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#####################################################\n",
    "#           Data Loading\n",
    "#####################################################\n",
    "\n",
    "with open(\"im2age_map_test.json\", 'r') as im2age_map_test_f:\n",
    "    im2age_map_test = json.load(im2age_map_test_f)\n",
    "\n",
    "# Load data\n",
    "data_parser = DataParser('../Common/Datasets/Morph2/aligned_data/aligned_dataset_with_metadata_uint8.hdf5', small_data=cfg.SMALL_DATA)\n",
    "data_parser.initialize_data()\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = data_parser.x_train,\tdata_parser.y_train, data_parser.x_test, data_parser.y_test,\n",
    "if cfg.RANDOM_SPLIT:\n",
    "    all_images = np.concatenate((x_train, x_test), axis=0)\n",
    "    all_labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=cfg.TEST_SIZE_FOR_RS, random_state=cfg.RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02804075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proj\\.conda\\envs\\my_thesis_py38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1361: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (q trn, r trn) set size: 44285\n",
      "Testing (q tst, r tst) set size: 10606\n",
      "Testing (q tst, r trn) set size: 10606\n",
      "Testing (q tst where AgePredict(q)  0 <= error <= 35, r trn where age(r)=AgePredict(q)) set size: 7012\n"
     ]
    }
   ],
   "source": [
    "face2emb_arr_trn_r = np.load('face2emb_arr_trn.npy', allow_pickle=True)\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "#face2emb_arr_trn_r = face2emb_arr_trn_r.item()\n",
    "\n",
    "face2emb_arr_vld_r = np.load('face2emb_arr_vld.npy', allow_pickle=True)\n",
    "#face2emb_arr_vld_r = face2emb_arr_vld_r.item()\n",
    "\n",
    "# shuffle basic aligned test\n",
    "# x_test_shuffled\n",
    "# y_test_shuffled\n",
    "\n",
    "\n",
    "transf = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, (0.9, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1,\n",
    "            saturation=0.1,\n",
    "            hue=0.1\n",
    "        )], p=0.5),\n",
    "        transforms.RandomApply([transforms.RandomAffine(\n",
    "            degrees=10,\n",
    "            translate=(0.1, 0.1),\n",
    "            scale=(0.9, 1.1),\n",
    "            shear=5,\n",
    "            resample=Image.BICUBIC\n",
    "        )], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.5)\n",
    "    ])\n",
    "\n",
    "# transf = transforms.Compose([\n",
    "#         transforms.Resize(224), # just for testing\n",
    "# #          transforms.RandomResizedCrop(224, (0.9, 1.0)),\n",
    "# #          transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomApply([transforms.ColorJitter(\n",
    "#             brightness=0.1,\n",
    "#             contrast=0.1,\n",
    "#             saturation=0.1,\n",
    "#             hue=0.1\n",
    "#         )], p=0.5),\n",
    "# #         transforms.RandomApply([transforms.RandomAffine(\n",
    "# #             degrees=10,\n",
    "# #             translate=(0.1, 0.1),\n",
    "# #             scale=(0.9, 1.1),\n",
    "# #             shear=5,\n",
    "# #             resample=Image.BICUBIC\n",
    "# #         )], p=0.5),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# #        transforms.RandomErasing(p=0.5)\n",
    "# ])\n",
    "\n",
    "train_ds = DiffPipeline4SameUniformDiffDataset(\n",
    "    data_set_images=x_train,\n",
    "    data_set_metadata=y_train,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS,\n",
    "    age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "    age_diff_learn_radius_hi=3,#cfg.AGE_DIFF_LEARN_RADIUS_HI,\n",
    "    embs=face2emb_arr_trn_r,\n",
    "    #num_references=cfg.NUM_OF_REFS\n",
    ")\n",
    "\n",
    "print(\"Training (q trn, r trn) set size: \" + str(len(train_ds)))\n",
    "\n",
    "test_qtst_rtst_ds = DiffPipeline4SameUniformDiffDataset(\n",
    "    data_set_images=x_test,\n",
    "    data_set_metadata=y_test,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS,\n",
    "    age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "    age_diff_learn_radius_hi=3,#cfg.AGE_DIFF_LEARN_RADIUS_HI,\n",
    "    embs=face2emb_arr_vld_r,\n",
    "    #num_references=cfg.NUM_OF_REFS\n",
    ")\n",
    "\n",
    "print(\"Testing (q tst, r tst) set size: \" + str(len(test_qtst_rtst_ds)))\n",
    "\n",
    "test_qtst_rtrn_ds = DiffPipeline4MixedUniformDiffDataset(\n",
    "    batrn_set_images=x_train,\n",
    "    batrn_set_metadata=y_train,\n",
    "    batst_set_images=x_test,\n",
    "    batst_set_metadata=y_test,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS,\n",
    "    age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "    age_diff_learn_radius_hi=3,#cfg.AGE_DIFF_LEARN_RADIUS_HI,\n",
    "    embs_trn=face2emb_arr_trn_r,\n",
    "    embs_vld=face2emb_arr_vld_r,\n",
    "    #num_references=cfg.NUM_OF_REFS\n",
    ")\n",
    "\n",
    "print(\"Testing (q tst, r trn) set size: \" + str(len(test_qtst_rtrn_ds)))\n",
    "\n",
    "x_test_filtered, y_test_filtered, batst_set_filtered_indexes = get_error_constrained_dataset(orig_dataset_images=x_test, \n",
    "                                                                                                orig_dataset_metadata=y_test,\n",
    "                                                                                                age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "                                                                                                age_diff_learn_radius_hi=3,#cfg.AGE_DIFF_LEARN_RADIUS_HI,\n",
    "                                                                                                im2age_map_batst=im2age_map_test)\n",
    "\n",
    "# apref = Age Predict Reference (dataset is based on (q,r) pairs where r's age is what AgePredict model returns on q)\n",
    "test_apref_ds = DiffPipeline4MimicDiffDataset(\n",
    "    batrn_set_images=x_train,\n",
    "    batrn_set_metadata=y_train,\n",
    "    batst_set_images=x_test_filtered,\n",
    "    batst_set_metadata=y_test_filtered,\n",
    "    batst_set_indexes=batst_set_filtered_indexes,\n",
    "    im2age_map_batst=im2age_map_test,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS,\n",
    "    embs_trn=face2emb_arr_trn_r,\n",
    "    embs_vld=face2emb_arr_vld_r,\n",
    "    #num_references=cfg.NUM_OF_REFS\n",
    ")\n",
    "\n",
    "print(\"Testing (q tst where AgePredict(q)  {age_diff_learn_radius_lo} <= error <= {age_diff_learn_radius_hi}, r trn where age(r)=AgePredict(q)) set size: \".format(age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO, age_diff_learn_radius_hi=cfg.AGE_DIFF_LEARN_RADIUS_HI) + str(len(test_apref_ds)))\n",
    "\n",
    "x_test_all, y_test_all, batst_set_all_indexes = get_error_constrained_dataset(orig_dataset_images=x_test, \n",
    "                                                                                                orig_dataset_metadata=y_test,\n",
    "                                                                                                age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "                                                                                                age_diff_learn_radius_hi=3,#35,#cfg.AGE_RADIUS,\n",
    "                                                                                                im2age_map_batst=im2age_map_test)\n",
    "\n",
    "\n",
    "# apref = Age Predict Reference (dataset is based on (q,r) pairs where r's age is what AgePredict model returns on q)\n",
    "# test_apref_all_ds = DiffPipeline4MimicDiffDataset(\n",
    "# \tbatrn_set_images=x_train,\n",
    "# \tbatrn_set_metadata=y_train,\n",
    "#     batst_set_images=x_test_all,\n",
    "#     batst_set_metadata=y_test_all,\n",
    "#     batst_set_indexes=batst_set_all_indexes,\n",
    "#     im2age_map_batst=im2age_map_test,\n",
    "# \tmin_age=cfg.MIN_AGE,\n",
    "# \tage_interval=cfg.AGE_INTERVAL,\n",
    "#     max_age=cfg.MAX_AGE,\n",
    "# \ttransform=transf,\n",
    "#     copies=1, \n",
    "#     age_radius=cfg.AGE_RADIUS,\n",
    "#     embs_trn=face2emb_arr_trn_r,\n",
    "#     embs_vld=face2emb_arr_vld_r#,\n",
    "#     #num_references=cfg.NUM_OF_REFS\n",
    "# )\n",
    "\n",
    "# print(\"Testing (q tst where AgePredict(q)  {age_diff_learn_radius_lo} <= error <= {age_diff_learn_radius_hi}, r trn where age(r)=AgePredict(q)) set size: \".format(age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO, age_diff_learn_radius_hi=35) + str(len(test_apref_all_ds))) #cfg.AGE_RADIUS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_ds,\n",
    "    'val_qtst_rtst': test_qtst_rtst_ds,\n",
    "    'val_qtst_rtrn': test_qtst_rtrn_ds,\n",
    "    'val_apref_ds': test_apref_ds,\n",
    "    #'val_apref_all_ds': test_apref_all_ds\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val_qtst_rtst', 'val_qtst_rtrn', 'val_apref_ds']}#, 'val_apref_all_ds']}\n",
    "\n",
    "data_loaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=True, drop_last=True),\n",
    "    'val_qtst_rtst': DataLoader(test_qtst_rtst_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True),\n",
    "    'val_qtst_rtrn': DataLoader(test_qtst_rtrn_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True),\n",
    "    'val_apref_ds': DataLoader(test_apref_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True),\n",
    "    #'val_apref_all_ds' : DataLoader(test_apref_all_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee18dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1383/1383 [27:54<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_sample = np.array([])\n",
    "for i, batch in enumerate(tqdm(data_loaders['train'])):\n",
    "    total_sample = np.concatenate((total_sample, batch['age_diff'].numpy()))\n",
    "#     if i % 5 == 0:\n",
    "#         print(np.histogram(total_sample, bins=[-3,-2,-1,0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f762e221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6619., 6647.,    0., 6454.,    0., 6637., 6299.,    0., 5953.,\n",
       "        5647.]),\n",
       " array([-3. , -2.4, -1.8, -1.2, -0.6,  0. ,  0.6,  1.2,  1.8,  2.4,  3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdfce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
