{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a3fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# importing the sys module\n",
    "import sys        \n",
    " \n",
    "# appending the directory of mod.py\n",
    "# in the sys.path list\n",
    "sys.path.append('../')   \n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from Common.Optimizers.RangerLars import RangerLars\n",
    "from Common.Schedulers.GradualWarmupScheduler import GradualWarmupScheduler\n",
    "\n",
    "import range_classification__config as cfg\n",
    "\n",
    "from range_classification__dataset import RangeClassificationSameUniformDiffDataset, RangeClassificationMixedUniformDiffDataset, RangeClassificationMimicDiffDataset, get_error_constrained_dataset\n",
    "from Common.Datasets.Morph2.data_parser import DataParser\n",
    "from range_classification__train import train_diff_cls_model_iter\n",
    "\n",
    "\n",
    "from range_classification__model import RangeClassificationModel, RangeClassificationDeepModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from condor_pytorch.metrics import mean_absolute_error\n",
    "from condor_pytorch.dataset import levels_from_labelbatch\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efc5a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MULTI_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50f9341",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/projects/age_estimation/RangeClassPipeline/weights/Morph2Diff/unified/iter/time_01_09_2022_13_54_07\\\\weights.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m age_diff_model_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(age_diff_model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[1;32m----> 5\u001b[0m file_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mage_diff_model_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m new_file_dict \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m file_dict:\n",
      "File \u001b[1;32m~\\.conda\\envs\\my_thesis_py38\\lib\\site-packages\\torch\\serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    592\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\.conda\\envs\\my_thesis_py38\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\.conda\\envs\\my_thesis_py38\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/projects/age_estimation/RangeClassPipeline/weights/Morph2Diff/unified/iter/time_01_09_2022_13_54_07\\\\weights.pt'"
     ]
    }
   ],
   "source": [
    "age_diff_model_path = 'D:/projects/age_estimation/RangeClassPipeline/weights/Morph2Diff/unified/iter/time_01_09_2022_13_54_07'\n",
    "age_diff_model_file = os.path.join(age_diff_model_path, \"weights.pt\")\n",
    "\n",
    "from collections import OrderedDict\n",
    "file_dict = torch.load(age_diff_model_file)\n",
    "new_file_dict = OrderedDict()\n",
    "for x in file_dict:\n",
    "    new_file_dict[x.split('module.')[1]] = file_dict[x] #new_file_dict[]\n",
    "    \n",
    "new_file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7737a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff592627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_diff_range_predictor(age_interval, min_age, max_age, age_radius, device, age_diff_range_model):\n",
    "    #age_diff_model_inst = age_diff_model(age_interval, min_age, max_age, age_radius, device, deep, num_references, config_type, added_embed_layer_size, diff_embed_layer_size, is_ordinal_reg)\n",
    "    age_diff_range_model_inst = age_diff_range_model(age_interval, min_age, max_age, age_radius, device) #, config_type, added_embed_layer_size, diff_embed_layer_size, is_ordinal_reg)\n",
    "\n",
    "\n",
    "    if cfg.USE_GPU and cfg.MULTI_GPU:\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using multiple GPUs (\" + str(torch.cuda.device_count()) + \")\")\n",
    "            age_diff_model_inst = torch.nn.DataParallel(age_diff_range_model_inst)\n",
    "\n",
    "\n",
    "\n",
    "    print(age_diff_range_model_inst)\n",
    "    age_diff_model_path = 'D:/projects/age_estimation/RangeClassPipeline/weights/Morph2Diff/unified/iter/time_01_09_2022_13_54_07'\n",
    "    age_diff_model_file = os.path.join(age_diff_model_path, \"weights.pt\")\n",
    "\n",
    "    file_dict = torch.load(age_diff_model_file)\n",
    "    new_file_dict = OrderedDict()\n",
    "    for x in file_dict:\n",
    "        new_file_dict[x.split('module.')[1]] = file_dict[x] #new_file_dict[]\n",
    "\n",
    "\n",
    "\n",
    "    age_diff_range_model_inst.load_state_dict(new_file_dict) #torch.load(age_diff_model_file))#, strict=False)\n",
    "    age_diff_range_model_inst.to(device)\n",
    "\n",
    "    return age_diff_range_model_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#           Preparations\n",
    "#####################################################\n",
    "\n",
    "torch.manual_seed(cfg.RANDOM_SEED)\n",
    "np.random.seed(cfg.RANDOM_SEED)\n",
    "random.seed(cfg.RANDOM_SEED)\n",
    "\n",
    "if cfg.USE_GPU:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#####################################################\n",
    "#           Data Loading\n",
    "#####################################################\n",
    "\n",
    "with open(\"im2age_map_test.json\", 'r') as im2age_map_test_f:\n",
    "    im2age_map_test = json.load(im2age_map_test_f)\n",
    "\n",
    "# Load data\n",
    "data_parser = DataParser('../Common/Datasets/Morph2/aligned_data/aligned_dataset_with_metadata_uint8.hdf5', small_data=cfg.SMALL_DATA)\n",
    "data_parser.initialize_data()\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = data_parser.x_train,\tdata_parser.y_train, data_parser.x_test, data_parser.y_test,\n",
    "if cfg.RANDOM_SPLIT:\n",
    "    all_images = np.concatenate((x_train, x_test), axis=0)\n",
    "    all_labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=cfg.TEST_SIZE_FOR_RS, random_state=cfg.RANDOM_SEED)\n",
    "\n",
    "\n",
    "# shuffle basic aligned test\n",
    "# x_test_shuffled\n",
    "# y_test_shuffled\n",
    "\n",
    "\n",
    "transf = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, (0.9, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1,\n",
    "            saturation=0.1,\n",
    "            hue=0.1\n",
    "        )], p=0.5),\n",
    "        transforms.RandomApply([transforms.RandomAffine(\n",
    "            degrees=10,\n",
    "            translate=(0.1, 0.1),\n",
    "            scale=(0.9, 1.1),\n",
    "            shear=5,\n",
    "            resample=Image.BICUBIC\n",
    "        )], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.5)\n",
    "    ])\n",
    "\n",
    "train_ds = RangeClassificationSameUniformDiffDataset(\n",
    "    data_set_images=x_train,\n",
    "    data_set_metadata=y_train,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS,\n",
    "    age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "    age_diff_learn_radius_hi=cfg.AGE_DIFF_LEARN_RADIUS_HI\n",
    ")\n",
    "\n",
    "print(\"Training (q trn, r trn) set size: \" + str(len(train_ds)))\n",
    "\n",
    "\n",
    "\n",
    "x_test_filtered, y_test_filtered, batst_set_filtered_indexes = get_error_constrained_dataset(orig_dataset_images=x_test, \n",
    "                                                                                                orig_dataset_metadata=y_test,\n",
    "                                                                                                age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO,\n",
    "                                                                                                age_diff_learn_radius_hi=cfg.AGE_DIFF_LEARN_RADIUS_HI,\n",
    "                                                                                                im2age_map_batst=im2age_map_test)\n",
    "\n",
    "#apref = Age Predict Reference (dataset is based on (q,r) pairs where r's age is what AgePredict model returns on q)\n",
    "test_apref_ds = RangeClassificationMimicDiffDataset(\n",
    "    batrn_set_images=x_train,\n",
    "    batrn_set_metadata=y_train,\n",
    "    batst_set_images=x_test,#x_test_filtered,\n",
    "    batst_set_metadata=y_test,#y_test_filtered,\n",
    "    batst_set_indexes=batst_set_filtered_indexes,\n",
    "    im2age_map_batst=im2age_map_test,\n",
    "    min_age=cfg.MIN_AGE,\n",
    "    age_interval=cfg.AGE_INTERVAL,\n",
    "    max_age=cfg.MAX_AGE,\n",
    "    transform=transf,\n",
    "    copies=1, \n",
    "    age_radius=cfg.AGE_RADIUS\n",
    ")\n",
    "\n",
    "print(\"Testing (q tst where AgePredict(q)  {age_diff_learn_radius_lo} <= error <= {age_diff_learn_radius_hi}, r trn where age(r)=AgePredict(q)) set size: \".format(age_diff_learn_radius_lo=cfg.AGE_DIFF_LEARN_RADIUS_LO, age_diff_learn_radius_hi=cfg.AGE_DIFF_LEARN_RADIUS_HI) + str(len(test_apref_ds)))\n",
    "\n",
    "\n",
    "image_datasets = {\n",
    "    'val_apref_ds': test_apref_ds\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['val_apref_ds']}\n",
    "\n",
    "data_loaders = {\n",
    "    'val_apref_ds': DataLoader(test_apref_ds, batch_size=cfg.BATCH_SIZE, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RangeClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731acdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg.USE_GPU and cfg.MULTI_GPU:\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             print(\"Using multiple GPUs (\" + str(torch.cuda.device_count()) + \")\")\n",
    "#             model = torch.nn.DataParallel(model)\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_range_pipeline_confusion_matrix_analysis(model, val_data_loader, device, dataset_size):\n",
    "    print('running on validation set...')\n",
    "\n",
    "    pred_full = np.array([])\n",
    "    labels_cls = np.array([])\n",
    "\n",
    "    limit = -1\n",
    "    for i, batch in enumerate(tqdm(val_data_loader)):\n",
    "        inputs = batch['image_vec'].to(device) #batch['image_vec'][:,:2,:,:,:].to(device)\n",
    "        labels = batch['label'].to(device).float()\n",
    "        age_diff = batch['age_diff'].to(device).float()  \n",
    "\n",
    "        #with torch.no_grad():\n",
    "        classification_logits = model(inputs)\n",
    "        \n",
    "        _, age_diff_pred_hard = torch.max(classification_logits, 1)\n",
    "\n",
    "\n",
    "        pred = age_diff_pred_hard.detach().to('cpu').numpy()\n",
    "\n",
    "        labels_cls = np.concatenate((labels_cls, labels.to('cpu').numpy()), axis=0)\n",
    "\n",
    "        pred_full = np.concatenate((pred_full, pred), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if limit != -1:\n",
    "            if i == limit-1:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    print(len(pred_full))\n",
    "    print()\n",
    "\n",
    "    class_names = [0,1,2] #range(-cfg.AGE_RADIUS, cfg.AGE_RADIUS + 1)]\n",
    "    cnf_matrix = metrics.confusion_matrix(labels_cls, pred_full, labels=[0,1,2])\n",
    "    seaborn.heatmap(pd.DataFrame(data=cnf_matrix, index=class_names, columns=class_names), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('Actual Label')\n",
    "\n",
    "    plt.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_predictor = get_age_diff_range_predictor(cfg.AGE_INTERVAL, cfg.MIN_AGE, cfg.MAX_AGE, cfg.AGE_RADIUS, device, model)\n",
    "age_diff_predictor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_loader = data_loaders['val_apref_ds']\n",
    "dataset_size = dataset_sizes['val_apref_ds']\n",
    "diff_range_pipeline_confusion_matrix_analysis(age_diff_predictor, val_data_loader, device, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "8801/10606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_filtered, y_test_filtered, batst_set_filtered_indexes = get_error_constrained_dataset(orig_dataset_images=x_test, \n",
    "#                                                                                                 orig_dataset_metadata=y_test,\n",
    "#                                                                                                 age_diff_learn_radius_lo=0,\n",
    "#                                                                                                 age_diff_learn_radius_hi=2,\n",
    "#                                                                                                 im2age_map_batst=im2age_map_test)\n",
    "# print(len(x_test_filtered))\n",
    "\n",
    "# x_test_filtered, y_test_filtered, batst_set_filtered_indexes = get_error_constrained_dataset(orig_dataset_images=x_test, \n",
    "#                                                                                                 orig_dataset_metadata=y_test,\n",
    "#                                                                                                 age_diff_learn_radius_lo=2,\n",
    "#                                                                                                 age_diff_learn_radius_hi=4,\n",
    "#                                                                                                 im2age_map_batst=im2age_map_test)\n",
    "# print(len(x_test_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5d883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5d732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
