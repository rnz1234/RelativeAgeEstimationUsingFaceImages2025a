{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#\tProject\t\t:\tAge Estimation\n",
    "#\tPipeline\t:\tE2ePipeline3\n",
    "#\tDate\t\t:\t1.11.2023\n",
    "# \tDescription\t: \tBias Analysis\n",
    "##############################################################################\n",
    "\n",
    "import shutil\n",
    "\n",
    "# importing the sys module\n",
    "import sys        \n",
    " \n",
    "# appending the directory of mod.py\n",
    "# in the sys.path list\n",
    "sys.path.append('../')   \n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from datetime import datetime\n",
    "from Common.Datasets.Morph2.data_parser import DataParser\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Common.Optimizers.RangerLars import RangerLars\n",
    "from Common.Schedulers.GradualWarmupScheduler import GradualWarmupScheduler\n",
    "from Common.Analysis.GeneralMethods import get_statistics\n",
    "from Common.Datasets.CACD.CacdDataParser import CacdDataParser\n",
    "from Common.Datasets.Morph2.dataset_utils import *\n",
    "\n",
    "import ep3_config as cfg\n",
    "from ep3_dataset import QueryAndMultiAgeRefsDataset\n",
    "from ep3_model import DiffBasedAgeDetectionModel\n",
    "from ep3_train import train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#           Preparations\n",
    "#####################################################\n",
    "\n",
    "torch.manual_seed(cfg.RANDOM_SEED)\n",
    "np.random.seed(cfg.RANDOM_SEED)\n",
    "random.seed(cfg.RANDOM_SEED)\n",
    "\n",
    "if cfg.USE_GPU:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#####################################################\n",
    "#           Data Loading\n",
    "#####################################################\n",
    "\n",
    "# Load data\n",
    "print(f\"Dataset: {cfg.DATASET_SELECT}\")\n",
    "print(\"Reading dataset...\")\n",
    "\n",
    "# Load data\n",
    "if cfg.DATASET_SELECT == \"Morph2\":\n",
    "\tdata_parser = DataParser(cfg.MORPH2_DATASET_PATH, small_data=cfg.SMALL_DATA)\n",
    "\tdata_parser.initialize_data()\n",
    "\tx_train, y_train, x_test, y_test, chosen_idxs_trn, chosen_idxs_tst = data_parser.x_train,\tdata_parser.y_train, data_parser.x_test, data_parser.y_test, data_parser.chosen_idxs_trn, data_parser.chosen_idxs_tst\n",
    "elif cfg.DATASET_SELECT == \"CACD\":\n",
    "\tdata_parser = CacdDataParser(cfg.CACD_DATASET_PATH)\n",
    "\tdata_parser.initialize_data()\n",
    "\tx_train, y_train, x_test, y_test = data_parser.x_train,\tdata_parser.y_train, data_parser.x_test, data_parser.y_test\n",
    "\n",
    "if cfg.RANDOM_SPLIT:\n",
    "    all_images = np.concatenate((x_train, x_test), axis=0)\n",
    "    all_labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=cfg.TEST_SIZE_FOR_RS, random_state=cfg.RANDOM_SEED)\n",
    "\n",
    "#####################################################\n",
    "#           Metadata Loading\n",
    "#####################################################\n",
    "\n",
    "# Emebeddings\n",
    "face2emb_arr_trn_r = np.load(f'{cfg.DATASET_SELECT}_face2emb_arr_trn_recog.npy', allow_pickle=True)\n",
    "face2emb_arr_vld_r = np.load(f'{cfg.DATASET_SELECT}_face2emb_arr_vld_recog.npy', allow_pickle=True)\n",
    "\n",
    "if cfg.SMALL_DATA:\n",
    "\tif cfg.APPLY_TRAIN_SET_SPLIT_FOR_DIST_AND_ISOL or cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\t\tprint(\"Unsupported modes from small data. Please cancel these modes and rerun. Aborting\")\n",
    "\t\texit()\n",
    "\n",
    "\tif cfg.DATASET_SELECT == \"Morph2\":\n",
    "\t\tface2emb_arr_trn_r = face2emb_arr_trn_r[chosen_idxs_trn]\n",
    "\t\tface2emb_arr_vld_r = face2emb_arr_vld_r[chosen_idxs_tst]\n",
    "\n",
    "# Base model inference results loading\n",
    "with open(cfg.INPUT_ESTIMATION_FILE_NAME_TEST, 'r') as im2age_map_test_f:\n",
    "\tim2age_map_test = json.load(im2age_map_test_f)\n",
    "                  \n",
    "with open(cfg.INPUT_ESTIMATION_FILE_NAME_TRAIN, 'r') as im2age_map_train_and_dist_f:\n",
    "\tim2age_map_train_and_dist = json.load(im2age_map_train_and_dist_f)\n",
    "                  \n",
    "\n",
    "\"\"\"\n",
    "Creatig now these for next stages:\n",
    "\n",
    "train actual\n",
    "test actual \n",
    "dist\n",
    "embeddings train actual\n",
    "embeddings test actual\n",
    "map test\n",
    "base_model_err_dist_on_non_trained_set\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if cfg.APPLY_TRAIN_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\tprint(\"applying dist and isol train sets split\")\n",
    "\t# load dist and isol test indexes\n",
    "\twith open(f'{cfg.INDEXES_SAVE_DIR}/{cfg.DATASET_SELECT}_dist_indexes.pkl', 'rb') as f_dist_indexes:\n",
    "\t\tdist_indexes = pickle.load(f_dist_indexes)\n",
    "\twith open(f'{cfg.INDEXES_SAVE_DIR}/{cfg.DATASET_SELECT}_isolated_train_indexes.pkl', 'rb') as f_isolated_train_indexes:\n",
    "\t\tisolated_train_indexes = pickle.load(f_isolated_train_indexes)\n",
    "\n",
    "\n",
    "\tprint(f\"Original train set size: {len(data_parser.y_train)}\")\n",
    "\n",
    "\tx_train_dist, y_train_dist, im2age_map_train_dist, x_train_isol, y_train_isol, im2age_map_train_isol = gen_dist_and_isol_test_sets(x_src_dataset=data_parser.x_train, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ty_src_dataset=data_parser.y_train, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tim2age_map_src_dataset_orig=im2age_map_train_and_dist, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdist_indexes=dist_indexes, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tisolated_src_dataset_indexed=isolated_train_indexes)\n",
    "\n",
    "\tprint(f\"Actual train set size: {len(y_train_isol)}\")\n",
    "\n",
    "\t# Outcome to next stages\n",
    "\tface2emb_arr_trn_r_actual = face2emb_arr_trn_r[isolated_train_indexes]\n",
    "\tface2emb_arr_vld_r_actual = face2emb_arr_vld_r\n",
    "\t\n",
    "\tbase_model_err_dist_on_non_trained_set = get_statistics(dataset_metadata=y_train_dist,\n",
    "\t\t\t\t\t\t\t\t\t\tdataset_indexes=[i for i in range(len(y_train_dist))], \n",
    "\t\t\t\t\t\t\t\t\t\tim2age_map_batst=im2age_map_train_dist)\n",
    "\t\n",
    "\t#print(f\"\"\"MAE (dist): {np.mean(np.abs(base_model_err_dist_on_non_trained_set[\"data\"]))}\"\"\")\n",
    "\t\n",
    "\t# train_set_stats = get_statistics(dataset_metadata=y_train_isol,\n",
    "\t# \t\t\t\t\t\t\t\t\tdataset_indexes=[i for i in range(len(y_train_isol))], \n",
    "\t# \t\t\t\t\t\t\t\t\tim2age_map_batst=im2age_map_train_isol)\n",
    "\t\n",
    "\t# print(f\"\"\"MAE (train): {np.mean(np.abs(train_set_stats[\"data\"]))}\"\"\")\n",
    "\t\n",
    "\t# test_set_stats = get_statistics(dataset_metadata=y_test,\n",
    "\t# \t\t\t\t\t\t\t\t\tdataset_indexes=[i for i in range(len(y_test))], \n",
    "\t# \t\t\t\t\t\t\t\t\tim2age_map_batst=im2age_map_test)\n",
    "\t\n",
    "\t# print(f\"\"\"MAE (test): {np.mean(np.abs(test_set_stats[\"data\"]))}\"\"\")\n",
    "\t\n",
    "\n",
    "\tx_test_actual = x_test\n",
    "\ty_test_actual = y_test\n",
    "\tx_train_actual = x_train_isol\n",
    "\ty_train_actual = y_train_isol\n",
    "\tim2age_map_test_actual = im2age_map_test\n",
    "elif cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\tprint(\"applying dist and isol test sets split\")\n",
    "\t# load dist and isol test indexes\n",
    "\twith open(f'{cfg.DATASET_SELECT}_dist_indexes.pkl', 'rb') as f_dist_indexes:\n",
    "\t\t\tdist_indexes = pickle.load(f_dist_indexes)\n",
    "\twith open(f'{cfg.DATASET_SELECT}_isolated_test_indexed.pkl', 'rb') as f_isolated_test_indexed:\n",
    "\t\t\tisolated_test_indexed = pickle.load(f_isolated_test_indexed)\n",
    "\n",
    "\tx_test_dist, y_test_dist, im2age_map_dist, x_test_isol, y_test_isol, im2age_map_isol = gen_dist_and_isol_test_sets(x_test, y_test, im2age_map_test, dist_indexes, isolated_test_indexed)\n",
    "\n",
    "\n",
    "\tface2emb_arr_vld_r_actual = face2emb_arr_vld_r[isolated_test_indexed]\n",
    "\n",
    "\ttest_err_distribution = get_statistics(dataset_metadata=y_test_dist,\n",
    "\t\t\t\t\t\t\t\t\t\tdataset_indexes=[i for i in range(len(y_test_dist))],#chosen_idxs_tst, \n",
    "\t\t\t\t\t\t\t\t\t\tim2age_map_batst=im2age_map_dist)\n",
    "\tx_test_actual = x_test_isol\n",
    "\ty_test_actual = y_test_isol\n",
    "\tim2age_map_test_actual = im2age_map_isol\n",
    "else:\n",
    "\tprint(\"NOT applying dist and isol test sets split\")\n",
    "\tface2emb_arr_vld_r_actual = face2emb_arr_vld_r\n",
    "    \n",
    "\ttest_err_distribution = get_statistics(dataset_metadata=y_test,\n",
    "\t\t\t\t\t\t\t\t\t\tdataset_indexes=[i for i in range(len(y_test))],#chosen_idxs_tst, \n",
    "\t\t\t\t\t\t\t\t\t\tim2age_map_batst=im2age_map_test)\n",
    "\tx_test_actual = x_test\n",
    "\ty_test_actual = y_test\n",
    "\tim2age_map_test_actual = im2age_map_test\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#           Dataset Creation\n",
    "#####################################################\n",
    "\n",
    "\n",
    "# Test - Transforms\n",
    "transf_tst = transforms.Compose([\n",
    "\t\t\ttransforms.Resize(224),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\t\t])\n",
    "\n",
    "\n",
    "# Train set\n",
    "if cfg.APPLY_TRAIN_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\t# The original train set is composed from the actual train set and dist set.\n",
    "\t# The dist is isolated from train set completely, hence it is kind of \"test set\".\n",
    "\t# So we use same settings used with test set definition (e.g. we don't use the \n",
    "\t# embeddings of the dist set as references). I.e. we run on dist set as if it \n",
    "\t# was \"test set\"\n",
    "\n",
    "\ttrain_ds = QueryAndMultiAgeRefsDataset(\n",
    "\t\tmin_age=cfg.MIN_AGE,\n",
    "\t\tmax_age=cfg.MAX_AGE,\n",
    "\t\tage_interval=cfg.AGE_INTERVAL,\n",
    "\t\ttransform=transf_tst,\n",
    "\t\tnum_references=cfg.NUM_REFERENCES,\n",
    "\t\tembeddings_knn=cfg.EMBEDDINGS_KNN,\n",
    "\t\tbase_data_set_images=x_train,                \n",
    "\t\tbase_data_set_metadata=y_train,   \n",
    "\t\tbase_data_set_embeddings=face2emb_arr_trn_r,            \n",
    "\t\tref_data_set_images=x_train_actual,                \n",
    "\t\tref_data_set_metadata=y_train_actual,              \n",
    "\t\tref_data_set_embeddings=face2emb_arr_trn_r_actual,\n",
    "\t\tdataset_size_factor=cfg.DATASET_SIZE_FACTOR,\n",
    "\t\tbase_set_is_ref_set=False,\n",
    "\t\tdisable_same_ref_being_query=False,\n",
    "\t\tknn_reduced_pool_size=cfg.KNN_REDUCED_POOL_SIZE,\n",
    "\t\tsample_knn_reduced_pool=True,\n",
    "\t\tbase_model_distribution=None,\n",
    "\t\tim2age_map=im2age_map_train_and_dist,\n",
    "\t\tmode_select=\"apply_map\"\n",
    "\t\t)\n",
    "\t\n",
    "\tprint(\"Train+Dist (q vld, r trn) set size: \" + str(len(train_ds)))\n",
    "\t\n",
    "\n",
    "# Test set\n",
    "test_ds = QueryAndMultiAgeRefsDataset(\n",
    "\tmin_age=cfg.MIN_AGE,\n",
    "\tmax_age=cfg.MAX_AGE,\n",
    "\tage_interval=cfg.AGE_INTERVAL,\n",
    "\ttransform=transf_tst,\n",
    "\tnum_references=cfg.NUM_REFERENCES,\n",
    "\tembeddings_knn=cfg.EMBEDDINGS_KNN,\n",
    "\tbase_data_set_images=x_test,                \n",
    "\tbase_data_set_metadata=y_test,   \n",
    "\tbase_data_set_embeddings=face2emb_arr_vld_r,            \n",
    "\tref_data_set_images=x_train,                \n",
    "\tref_data_set_metadata=y_train,              \n",
    "\tref_data_set_embeddings=face2emb_arr_trn_r,\n",
    "\tdataset_size_factor=cfg.DATASET_SIZE_FACTOR,\n",
    "\tbase_set_is_ref_set=False,\n",
    "\tdisable_same_ref_being_query=False,\n",
    "\tknn_reduced_pool_size=cfg.KNN_REDUCED_POOL_SIZE,\n",
    "\tsample_knn_reduced_pool=True,\n",
    "    base_model_distribution=None,\n",
    "\tim2age_map=im2age_map_test,\n",
    "\tmode_select=\"apply_map\"\n",
    "    )\n",
    "\n",
    "print(\"Testing (q vld, r trn) set size: \" + str(len(test_ds)))\n",
    "\n",
    "if cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\ttest_isol_ds = QueryAndMultiAgeRefsDataset(\n",
    "\t\tmin_age=cfg.MIN_AGE,\n",
    "\t\tmax_age=cfg.MAX_AGE,\n",
    "\t\tage_interval=cfg.AGE_INTERVAL,\n",
    "\t\ttransform=transf_tst,\n",
    "\t\tnum_references=cfg.NUM_REFERENCES,\n",
    "\t\tembeddings_knn=cfg.EMBEDDINGS_KNN,\n",
    "\t\tbase_data_set_images=x_test_actual,                \n",
    "\t\tbase_data_set_metadata=y_test_actual,   \n",
    "\t\tbase_data_set_embeddings=face2emb_arr_vld_r_actual,            \n",
    "\t\tref_data_set_images=x_train,                \n",
    "\t\tref_data_set_metadata=y_train,              \n",
    "\t\tref_data_set_embeddings=face2emb_arr_trn_r,\n",
    "\t\tdataset_size_factor=cfg.DATASET_SIZE_FACTOR,\n",
    "\t\tbase_set_is_ref_set=False,\n",
    "\t\tdisable_same_ref_being_query=False,\n",
    "\t\tknn_reduced_pool_size=cfg.KNN_REDUCED_POOL_SIZE,\n",
    "\t\tsample_knn_reduced_pool=True,\n",
    "\t\tbase_model_distribution=None,\n",
    "\t\tim2age_map=im2age_map_test_actual,\n",
    "\t\tmode_select=\"apply_map\"\n",
    "\t\t)\n",
    "\n",
    "\tprint(\"Testing isolated (q vld, r trn) set size: \" + str(len(test_isol_ds)))\n",
    "\n",
    "\n",
    "# full test \n",
    "image_datasets = {\n",
    "    'val_full' : test_ds\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['val_full']}\n",
    "\n",
    "data_loaders = {\n",
    "    'val_full': DataLoader(test_ds, batch_size=1, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=False),\n",
    "}\n",
    "\n",
    "# other sets\n",
    "if cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\timage_datasets['val_isol'] = test_isol_ds\n",
    "\tdataset_sizes['val_isol'] = len(image_datasets['val_isol'])\n",
    "\tdata_loaders['val_isol'] = DataLoader(test_isol_ds, batch_size=1, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=False)\n",
    "\n",
    "if cfg.APPLY_TRAIN_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\timage_datasets['train'] = train_ds\n",
    "\tdataset_sizes['train'] = len(image_datasets['train'])\n",
    "\tdata_loaders['train'] = DataLoader(train_ds, batch_size=1, num_workers=cfg.NUM_OF_WORKERS_DATALOADER, pin_memory=True, shuffle=False, drop_last=False)\n",
    "\n",
    "\n",
    "if cfg.DIST_APPROX_METHOD == \"kde_based_saturated\":\n",
    "\tmin_age_diff = cfg.ERROR_SAT_RANGE_MIN\n",
    "\tmax_age_diff = cfg.ERROR_SAT_RANGE_MAX\n",
    "else:\n",
    "\tmin_age_diff = cfg.MIN_AGE - cfg.MAX_AGE \n",
    "\tmax_age_diff = cfg.MAX_AGE - cfg.MIN_AGE \n",
    "\t\n",
    "num_classes_diff = max_age_diff - min_age_diff + 1\n",
    "print(f\"num of diff classes: {num_classes_diff}\")\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#           Model\n",
    "#####################################################\n",
    "\n",
    "model = DiffBasedAgeDetectionModel(\n",
    "    device=device,\n",
    "\tmin_age=cfg.MIN_AGE,\n",
    "\tmax_age=cfg.MAX_AGE,\n",
    "\tage_interval=cfg.AGE_INTERVAL,\n",
    "\tnum_references=cfg.NUM_REFERENCES,\n",
    "\tpretrained_model_path=cfg.PRETRAINED_MODEL_PATH,\n",
    "\tpretrained_model_file_name=cfg.PRETRAINED_MODEL_FILE_NAME,\n",
    "\tload_pretrained=cfg.LOAD_PRETRAINED_RECOG,\n",
    "\tdropout_p=cfg.DROPOUT_P,\n",
    "    num_of_fc_layers=cfg.NUM_OF_FC_LAYERS,\n",
    "    is_ordinal=cfg.IS_ORDINAL,\n",
    "    min_age_diff=min_age_diff,\n",
    "\tmax_age_diff=max_age_diff,\n",
    "\tnum_classes_diff=num_classes_diff,\n",
    "    regressors_diff_head=cfg.REGRESSORS_DIFF_HEAD,\n",
    "\tfc_head_base_layer_size=cfg.FC_HEAD_BASE_LAYER_SIZE,\n",
    "\tuse_vit=cfg.USE_VIT,\n",
    "\tuse_convnext=cfg.USE_CONVNEXT,\n",
    "\tuse_efficientnet=cfg.USE_EFFICIENTNET,\n",
    "\tuse_resnet51q=cfg.USE_RESNET51Q\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# if cfg.UNFREEZE_FEATURE_EXT_ON_RLVNT_EPOCH:\n",
    "#     model.freeze_base_cnn(True)\n",
    "\n",
    "if cfg.USE_GPU and cfg.MULTI_GPU:\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using multiple GPUs (\" + str(torch.cuda.device_count()) + \")\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "\n",
    "# test_err_distribution = get_statistics(dataset_metadata=y_test,\n",
    "#                                        dataset_indexes=[i for i in range(len(y_test))],#chosen_idxs_tst, \n",
    "#                                        im2age_map_batst=im2age_map_test)\n",
    "\n",
    "# mae_age = np.mean(np.abs(test_err_distribution[\"data\"]))\n",
    "# print(f\"MAE : {mae_age}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"loading weights...\")\n",
    "#loaded = torch.load(\"/home/eng/workspace/AgeEstimationMultiProject/E2ePipeline3/weights/Morph2Diff/unified/iter/time_24_12_2023_16_20_38/weights_54_2.5240.pt\")\n",
    "#loaded = torch.load(\"/home/eng/workspace/AgeEstimationMultiProject/E2ePipeline3/weights/Morph2Diff/unified/iter/time_08_01_2024_22_18_11/weights_59_2.5057.pt\")\n",
    "#loaded = torch.load(\"/home/eng/workspace/AgeEstimationMultiProject/E2ePipeline3/weights/Morph2Diff/unified/iter/time_17_01_2024_01_18_28/weights_19_2.4980.pt\")\n",
    "#loaded = torch.load(\"/home/eng/workspace/AgeEstimationMultiProject/E2ePipeline3/weights/Morph2Diff/unified/iter/time_19_01_2024_23_38_06/weights_19_2.4949.pt\")\n",
    "#loaded = torch.load(\"/home/eng/workspace/AgeEstimationMultiProject/E2ePipeline3/weights/Morph2Diff/unified/iter/time_20_01_2024_22_06_08/weights_1_2.4824.pt\")\n",
    "loaded = torch.load(cfg.INFERENCE_MODEL_WEIGHTS_PATH)\n",
    "model.load_state_dict(loaded['model_state_dict'], strict=True)#, map_location=torch.device('cuda:0')))#, strict=False)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in im2age_map_test_actual:\n",
    "# \tim2age_map_test_actual[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For later bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mae_age = 0.0\n",
    "\n",
    "im2age_map_next = dict()\n",
    "print(\"running inference...\")\n",
    "\n",
    "age_preds = []\n",
    "age_labels = []\n",
    "#class_preds = []\n",
    "#class_labels = []\n",
    "genders = []\n",
    "races = []\n",
    "\n",
    "\n",
    "if cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\trunning_mae_age_isol = 0.0\n",
    "\n",
    "\tprint(\"####################################################################\")\n",
    "\tprint(\"### Isolated test set (evaluation)\")\n",
    "\ti = 0\n",
    "\tfor batch in tqdm(data_loaders['val_isol']):\n",
    "\t\timage_vec = batch['image_vec'].to(device) #batch['image_vec'][:,:2,:,:,:].to(device)\n",
    "\t\tquery_age = batch['query_age'].to(device).float()\n",
    "\t\tquery_age_noised = batch['query_age_noised'].to(device).long()\n",
    "\t\tage_diff = batch['age_diffs_for_reg'].to(device).float() #torch.stack([batch['age_diffs_for_reg'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tage_refs = batch['age_refs'].to(device).long() #torch.stack([batch['age_refs'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tidxs = batch['actual_query_idx'].to(device)\n",
    "\n",
    "\t\t#class_label = batch['age_diffs_for_cls'].to(device).float()\n",
    "\t\tage_label = list(batch['query_age'].cpu().numpy())\n",
    "\t\t#print(age_label)\n",
    "\t\trace = batch['race']\n",
    "\t\tgender = batch['gender_raw']\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# age_pred, age_diff_preds = model(input_images=image_vec, input_ref_ages=age_refs)\n",
    "\t\t\t# age_loss = \tcriterion_age(age_pred.reshape(age_pred.shape[0]), query_age)\n",
    "\t\t\t# age_diff_loss = criterion_age_diff(age_diff_preds, age_diff)\n",
    "\t\t\tif cfg.USE_GENDER:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus, gender_head_cls_pre_sigmoid = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\telse:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\t\n",
    "\t\t\tif cfg.INFERENCE_BASED_ON_F:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_f.reshape(age_pred_f.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_f.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_preds.append(list(age_pred_f.cpu().numpy())[0][0])\n",
    "\t\t\telse:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_r.reshape(age_pred_r.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_r.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_preds.append(list(age_pred_r.cpu().numpy())[0][0])\n",
    "\n",
    "\t\t#print(list(age_pred_f.cpu().numpy()), age_label, gender, race)\n",
    "\n",
    "\t\t#_, class_pred = torch.max(classification_logits, 1)\n",
    "\t\t\n",
    "\t\tage_labels.append(age_label[0])\n",
    "\t\t#class_preds.append(class_pred)\n",
    "\t\t#class_labels.append(class_label)\n",
    "\t\tgenders.append(gender[0])\n",
    "\t\traces.append(race[0])\n",
    "\n",
    "\t\ti += 1\n",
    "\n",
    "\t\t# if i == 10:\n",
    "\t\t# \tbreak\n",
    "\n",
    "\tmae_age = running_mae_age_isol / dataset_sizes['val_isol']\n",
    "\tprint(f\"MAE (isolated test set): {mae_age}\")\n",
    "else:\n",
    "\trunning_mae_age_isol = 0.0\n",
    "\n",
    "\tprint(\"####################################################################\")\n",
    "\tprint(\"### Full test set (evaluation)\")\n",
    "\ti = 0\n",
    "\tfor batch in tqdm(data_loaders['val_full']):\n",
    "\t\timage_vec = batch['image_vec'].to(device) #batch['image_vec'][:,:2,:,:,:].to(device)\n",
    "\t\tquery_age = batch['query_age'].to(device).float()\n",
    "\t\tquery_age_noised = batch['query_age_noised'].to(device).long()\n",
    "\t\tage_diff = batch['age_diffs_for_reg'].to(device).float() #torch.stack([batch['age_diffs_for_reg'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tage_refs = batch['age_refs'].to(device).long() #torch.stack([batch['age_refs'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tidxs = batch['actual_query_idx'].to(device)\n",
    "\n",
    "\t\t#class_label = batch['age_diffs_for_cls'].to(device).float()\n",
    "\t\tage_label = list(batch['query_age'].cpu().numpy())\n",
    "\t\t#print(age_label)\n",
    "\t\trace = batch['race']\n",
    "\t\tgender = batch['gender_raw']\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# age_pred, age_diff_preds = model(input_images=image_vec, input_ref_ages=age_refs)\n",
    "\t\t\t# age_loss = \tcriterion_age(age_pred.reshape(age_pred.shape[0]), query_age)\n",
    "\t\t\t# age_diff_loss = criterion_age_diff(age_diff_preds, age_diff)\n",
    "\t\t\tif cfg.USE_GENDER:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus, gender_head_cls_pre_sigmoid = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\telse:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\t\n",
    "\n",
    "\t\t\tif cfg.INFERENCE_BASED_ON_F:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_f.reshape(age_pred_f.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_f.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_preds.append(list(age_pred_f.cpu().numpy())[0][0])\n",
    "\t\t\telse:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_r.reshape(age_pred_r.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_r.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_preds.append(list(age_pred_r.cpu().numpy())[0][0])\n",
    "\n",
    "\t\t#print(list(age_pred_f.cpu().numpy()), age_label, gender, race)\n",
    "\n",
    "\t\t#_, class_pred = torch.max(classification_logits, 1)\n",
    "\t\t\n",
    "\t\tage_labels.append(age_label[0])\n",
    "\t\t#class_preds.append(class_pred)\n",
    "\t\t#class_labels.append(class_label)\n",
    "\t\tgenders.append(gender[0])\n",
    "\t\traces.append(race[0])\n",
    "\n",
    "\t\ti += 1\n",
    "\n",
    "\t\t# if i == 10:\n",
    "\t\t# \tbreak\n",
    "\n",
    "\tmae_age = running_mae_age_isol / dataset_sizes['val_full']\n",
    "\tprint(f\"MAE (full test set): {mae_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "#data = {'age_preds': age_preds, 'age_labels': age_labels, 'class_labels': class_labels, 'class_preds': class_preds, 'genders': genders, 'races': races}\n",
    "data = {'age_preds': age_preds, 'age_labels': age_labels, 'genders': genders, 'races': races}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "race_dict = {'W':'White', 'B':'Black', 'H':'Hispanic', 'O':'Other', 'A':'Asian'}\n",
    "gender_dict = {'M':'Male', 'F':'Female'}\n",
    "\n",
    "# df['age_preds'] = df['age_preds'].apply(lambda x: x.cpu().detach().numpy()[0])\n",
    "# df['age_labels'] = df['age_labels'].apply(lambda x: x.cpu().detach().numpy()[0])\n",
    "# #df['class_preds'] = df['class_preds'].apply(lambda x: x.cpu().detach().numpy()[0])\n",
    "# #df['class_labels'] = df['class_labels'].apply(lambda x: x.cpu().detach().numpy()[0])\n",
    "\n",
    "df['genders'] = df['genders'].apply(lambda x: gender_dict[x])\n",
    "df['races'] = df['races'].apply(lambda x: race_dict[x])\n",
    "\n",
    "df = df[df['races'] != 'Other']\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abs_age_diff'] = np.abs(df['age_preds'] - df['age_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_good_eval_2_8_2025_morph2_effcientnetv2_best_2.45.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['age_labels'][0])\n",
    "# print(data[\"age_preds\"][0])\n",
    "# print(data[\"genders\"][0])\n",
    "# print(data[\"races\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg.INPUT_ESTIMATION_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Bias Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_BINS = 13\n",
    "\n",
    "ages = []\n",
    "for i in range(len(y_train)):\n",
    "\tmetadata = json.loads(y_train[i])\n",
    "\tage = int(metadata[\"age\"])\n",
    "\tages.append(age)\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "# \tmetadata = json.loads(y_test[i])\n",
    "# \tage = int(metadata[\"age\"])\n",
    "# \tages.append(age)\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "ages_a = np.array(ages)\n",
    "\n",
    "num_of_samples_train = dict()\n",
    "\n",
    "for bin_idx in range(NUM_OF_BINS):\n",
    "\tnum_of_samples_train[f\"{5*(bin_idx+3)}to{5*(bin_idx+3)+4}\"] = len(ages_a[(ages_a >= 5*(bin_idx+3)) & (ages_a <= 5*(bin_idx+3)+4)])\n",
    "\n",
    "#plt.hist(ages, bins=50)\n",
    "\n",
    "\n",
    "# age_ranges = {\n",
    "# \t\"15to19\": (15, 19),\n",
    "# \t\"20to24\": (20, 24),\n",
    "# \t\"25to29\": (25, 29),\n",
    "# \t\"30to34\": (30, 34),\n",
    "# \t\"35to39\": (35, 39),\n",
    "# \t\"40to44\": (40, 44),\n",
    "# \t\"45to49\": (45, 49),\n",
    "# \t\"50to54\": (50, 54),\n",
    "# \t\"55to59\": (55, 59),\n",
    "# \t\"60to64\": (60, 64),\n",
    "# \t\"65to70\": (65, 70)\n",
    "# }\n",
    "# ages = []\n",
    "# for i in range(len(y_train)):\n",
    "# \tmetadata = json.loads(y_train[i])\n",
    "# \tage = float(metadata[\"age\"])\n",
    "# \tages.append(age)\n",
    "# \tfor key, (lower, upper) in age_ranges.items():\n",
    "# \t\tif lower <= age <= upper:\n",
    "# \t\t\tnum_of_samples[f\"{lower}to{upper}\"] += 1\n",
    "# \t\t\tprint(lower, upper, age)\n",
    "# \t\t\tbreak\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "# \tmetadata = json.loads(y_test[i])\n",
    "# \tage = float(metadata[\"age\"])\n",
    "# \tfor key, (lower, upper) in age_ranges.items():\n",
    "# \t\tif lower <= age <= upper:\n",
    "# \t\t\tnum_of_samples[f\"{lower}to{upper}\"] += 1\n",
    "# \t\t\tbreak\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "print(\"running inference...\")\n",
    "\n",
    "error_bins = dict()\n",
    "for bin_idx in range(NUM_OF_BINS):\n",
    "\terror_bins[f\"{5*(bin_idx+3)}to{5*(bin_idx+3)+4}\"] = []\n",
    "\n",
    "\n",
    "\n",
    "if cfg.APPLY_TEST_SET_SPLIT_FOR_DIST_AND_ISOL:\n",
    "\trunning_mae_age_isol = 0.0\n",
    "\n",
    "\tprint(\"####################################################################\")\n",
    "\tprint(\"### Isolated test set (evaluation)\")\n",
    "\ti = 0\n",
    "\tfor batch in tqdm(data_loaders['val_isol']):\n",
    "\t\timage_vec = batch['image_vec'].to(device) #batch['image_vec'][:,:2,:,:,:].to(device)\n",
    "\t\tquery_age = batch['query_age'].to(device).float()\n",
    "\t\tquery_age_noised = batch['query_age_noised'].to(device).long()\n",
    "\t\tage_diff = batch['age_diffs_for_reg'].to(device).float() #torch.stack([batch['age_diffs_for_reg'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tage_refs = batch['age_refs'].to(device).long() #torch.stack([batch['age_refs'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tidxs = batch['actual_query_idx'].to(device)\n",
    "\n",
    "\t\t#class_label = batch['age_diffs_for_cls'].to(device).float()\n",
    "\t\tage_label = list(batch['query_age'].cpu().numpy())\n",
    "\t\t#print(age_label)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# age_pred, age_diff_preds = model(input_images=image_vec, input_ref_ages=age_refs)\n",
    "\t\t\t# age_loss = \tcriterion_age(age_pred.reshape(age_pred.shape[0]), query_age)\n",
    "\t\t\t# age_diff_loss = criterion_age_diff(age_diff_preds, age_diff)\n",
    "\t\t\tif cfg.USE_GENDER:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, gender_head_cls_pre_sigmoid = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\telse:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs)\n",
    "\t\t\t\n",
    "\t\t\tif cfg.INFERENCE_BASED_ON_F:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_f.reshape(age_pred_f.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_f.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_pred_used = list(age_pred_f.cpu().numpy())[0][0] \n",
    "\t\t\t\t#print(age_pred_f)\n",
    "\t\t\telse:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_r.reshape(age_pred_r.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_r.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_pred_used = list(age_pred_r.cpu().numpy())[0][0]\n",
    "\t\t\t\t#print(age_pred_r)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#print(age_label)\n",
    "\t\t\tbin_idx = int(math.floor(age_label[0] / 5)) - 3\n",
    "\t\t\t#print(bin_idx)\n",
    "\n",
    "\t\t\terror_bins[f\"{5*(bin_idx+3)}to{5*(bin_idx+3)+4}\"].append(age_pred_used-age_label[0])\n",
    "\n",
    "\n",
    "\t\t# i += 1\n",
    "\n",
    "\t\t# if i == 10:\n",
    "\t\t# \tbreak\n",
    "\n",
    "\tmae_age = running_mae_age_isol / dataset_sizes['val_isol']\n",
    "\tprint(f\"MAE (isolated test set): {mae_age}\")\n",
    "else:\n",
    "\trunning_mae_age_isol = 0.0\n",
    "\n",
    "\tprint(\"####################################################################\")\n",
    "\tprint(\"### Full test set (evaluation)\")\n",
    "\ti = 0\n",
    "\tfor batch in tqdm(data_loaders['val_full']):\n",
    "\t\timage_vec = batch['image_vec'].to(device) #batch['image_vec'][:,:2,:,:,:].to(device)\n",
    "\t\tquery_age = batch['query_age'].to(device).float()\n",
    "\t\tquery_age_noised = batch['query_age_noised'].to(device).long()\n",
    "\t\tage_diff = batch['age_diffs_for_reg'].to(device).float() #torch.stack([batch['age_diffs_for_reg'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tage_refs = batch['age_refs'].to(device).long() #torch.stack([batch['age_refs'][i].to(device).float() for i in range(num_references)])\n",
    "\t\tidxs = batch['actual_query_idx'].to(device)\n",
    "\n",
    "\t\t#class_label = batch['age_diffs_for_cls'].to(device).float()\n",
    "\t\tage_label = list(batch['query_age'].cpu().numpy())\n",
    "\t\t#print(age_label)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# age_pred, age_diff_preds = model(input_images=image_vec, input_ref_ages=age_refs)\n",
    "\t\t\t# age_loss = \tcriterion_age(age_pred.reshape(age_pred.shape[0]), query_age)\n",
    "\t\t\t# age_diff_loss = criterion_age_diff(age_diff_preds, age_diff)\n",
    "\t\t\tif cfg.USE_GENDER:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus, gender_head_cls_pre_sigmoid = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\telse:\n",
    "\t\t\t\tage_pred_f, age_pred_r, age_diff_preds_f, age_diff_preds_r, classification_logits, classification_logits_main_diff, classification_logits_main_diff_minus = model(input_images=image_vec, query_noisy_age=query_age_noised, input_ref_ages=age_refs) \n",
    "\t\t\t\t\n",
    "\t\t\tif cfg.INFERENCE_BASED_ON_F:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_f.reshape(age_pred_f.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_f.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_pred_used = list(age_pred_f.cpu().numpy())[0][0] \n",
    "\t\t\t\t#print(age_pred_f)\n",
    "\t\t\telse:\n",
    "\t\t\t\trunning_mae_age_isol += torch.nn.L1Loss()(age_pred_r.reshape(age_pred_r.shape[0]), query_age) * image_vec.size(0)\n",
    "\t\t\t\t#print(f\"age_pred : {age_pred_r.view(-1)}, age actual :{query_age}\")\n",
    "\t\t\t\tage_pred_used = list(age_pred_r.cpu().numpy())[0][0]\n",
    "\t\t\t\t#print(age_pred_r)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#print(age_label)\n",
    "\t\t\tbin_idx = int(math.floor(age_label[0] / 5)) - 3\n",
    "\t\t\t#print(bin_idx)\n",
    "\n",
    "\t\t\terror_bins[f\"{5*(bin_idx+3)}to{5*(bin_idx+3)+4}\"].append(age_pred_used-age_label[0])\n",
    "\n",
    "\n",
    "\t\t# i += 1\n",
    "\n",
    "\t\t# if i == 10:\n",
    "\t\t# \tbreak\n",
    "\n",
    "\tmae_age = running_mae_age_isol / dataset_sizes['val_full']\n",
    "\tprint(f\"MAE (Full test set): {mae_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_bins = dict()\n",
    "std_bins = dict()\n",
    "for bin in error_bins:\n",
    "\tif len(error_bins[bin]) > 0:\n",
    "\t\terr_arr = np.array(error_bins[bin])\n",
    "\t\tmae_bins[bin] = np.mean(np.abs(err_arr))\n",
    "\t\tstd_bins[bin] = np.std(err_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"age  |  #Samples  |  MAE  |  STD  \")\n",
    "for bin in mae_bins:\n",
    "\tprint(f\"{bin} & {num_of_samples_train[bin]} & {mae_bins[bin]} & {std_bins[bin]} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "for bin in error_bins:\n",
    "\tif len(error_bins[bin]) > 0:\n",
    "\t\terrs += error_bins[bin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(errs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
